"What does open-sourcing large language models actually entail?"
开源大模型到底开源什么？
ChatGPT的出现引发了一些关于开源的讨论，但需澄清一些常见的误解。开源通常指的是公开软件项目的源代码，例如Linux操作系统，但大语言模型的开源与此不同。
首先，源码开源只是开源的一部分。对于大多数人来说，获得大语言模型的源码并不会对他们产生直接帮助。源码包括模型结构和训练方法，但要达到与原始模型相似的性能，需要满足三个关键要素：算法、高算力和大数据。算法是大模型的核心部分，包括模型结构和训练方法。当源码开源时，只有极少数专家能够深入理解和修改它。对于绝大多数人来说，拥有源码并不会直接让他们能够轻松创建类似的模型。
除了算法，高算力和大数据也是至关重要的要素。运行大型语言模型需要大量计算资源，而且数据集的规模和质量对模型性能有重大影响。开源模型参数是有助于复现模型性能的一部分，但仍然需要足够的计算资源才能运行这些模型。通常，单卡运行这些模型需要显存超过60GB，这对于一般用户可能并不容易实现。
最后，开源数据集也是非常重要的。数据集的质量和规模对模型的训练和性能至关重要。目前中文大语言模型缺乏一些必要的数据，但已经有一些开源项目开始填补这个空白。
总之，大模型的开源涉及多个方面，包括源码、模型参数、数据集等,需要区分清楚：
源码开源：这指的是公开模型的源代码，包括模型结构和训练方法。源码开源允许研究者查看、修改和使用这些代码，以重新训练模型或进行相关研究。但源码开源并不意味着所有人都能轻松获得与原始模型相匹配的性能。
模型参数开源：这是指公开训练好的模型参数。模型参数包含了训练模型的所有知识，拿到这些参数后，可以用于推理和生成文本，而无需重新训练模型。这对于运行大语言模型非常重要，因为它们需要大量的计算资源来进行训练。
数据集开源：开源数据集包括用于训练和评估模型的数据。数据集的质量和规模对于模型的性能至关重要。开源数据集使研究者能够使用标记好的数据来训练模型，加速研究进展。
论文开源：虽然论文通常不需要开源，但许多研究者免费公开他们的研究论文，以分享他们的发现和方法。
大模型的开源通常包括源码和模型参数，有时也包括数据集。对于大多数人来说，模型参数才是最有价值的，因为拥有这些参数可以在不重新训练模型的情况下使用大型语言模型。然而，即使有模型参数，也需要大量的计算资源来运行这些模型，这是一个高门槛的挑战。
